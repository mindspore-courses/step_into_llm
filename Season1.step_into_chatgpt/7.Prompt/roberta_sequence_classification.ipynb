{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb7edc0-7482-448f-9dfe-b12cc7e1cab4",
   "metadata": {},
   "source": [
    "该实验可进行在线体验，在线体验链接（https://pangu.huaweicloud.com/gallery/asset-detail.html?id=016991f8-0e0d-44c8-96f7-8b2cad54c592\n",
    "）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabe994-5618-4f4f-9955-c8dc74870076",
   "metadata": {},
   "source": [
    "# 基于MindNLP的Roberta模型Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9aa619-6a28-4929-9c6c-2d88db8a1053",
   "metadata": {},
   "source": [
    "## 环境安装\n",
    "\n",
    "运行如下两个代码块，创建python-3.9.0 kernel。\n",
    "\n",
    "> 注意：\n",
    "> \n",
    ">此为在线运行平台配置python3.9的指南，如在其他环境平台运行案例，请根据实际情况修改如下代码\n",
    "> \n",
    "> 以下两个代码块仅能运行一次，多次运行会出现kernel报错。\n",
    ">\n",
    "> 如出现多次运行导致的kernel报错，请终止实例（点击右上角“停止NoteBook实例”的圆形图标），并重启实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0ef736-e7f1-46ac-866c-b6c76ef2c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c55998d-bdfc-45b5-b2e4-fb8d603a3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ee72f-e907-4536-b295-cc2f1c64db3c",
   "metadata": {},
   "source": [
    "创建完成后，稍等片刻，或刷新页面。如下图所示，点击右上角（或左上角）kernel选择python-3.9.0。\n",
    "\n",
    "![change-kernel](https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/ai-gallery/change-kernel.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75eb5c6-11a6-43df-9067-fa15622cd517",
   "metadata": {},
   "source": [
    "安装mindspore, mindnlp及其他依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bd85ef-29bf-40d5-8fef-00dfaab01a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install mindnlp\n",
    "!pip install ipywidgets\n",
    "!pip install tqdm==4.65.0\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7228a58b-4f81-4f5d-ac6c-d9439b3f4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "%env HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc505fa-31a4-4a07-8f9e-26bec54f4cdb",
   "metadata": {},
   "source": [
    "## 模型与数据集加载\n",
    "\n",
    "本案例对roberta-large模型基于GLUE基准数据集进行prompt tuning。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff5004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "\n",
      "Loading model cost 0.781 seconds.\n",
      "\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import mindspore\n",
    "from mindspore.experimental.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.engine import set_seed\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.modules.optimization import get_linear_schedule_with_warmup\n",
    "from mindnlp.peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptTuningConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32c4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_name_or_path = \"AI-ModelScope/roberta-large\"\n",
    "task = \"mrpc\"\n",
    "peft_type = PeftType.PROMPT_TUNING\n",
    "# num_epochs = 20\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf6f6e-2d5e-4342-b264-67c7419374d4",
   "metadata": {},
   "source": [
    "prompt tuning配置，任务类型选为\"SEQ_CLS\", 即序列分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "622fe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft config\n",
    "peft_config = PromptTuningConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=10)\n",
    "# learning rate\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474cad0-3b50-4ba1-aea4-2787955f41c7",
   "metadata": {},
   "source": [
    "加载tokenizer。如模型为GPT、OPT或BLOOM类模型，从序列左侧添加padding，其他情况下从序列右侧添加padding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e9efe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e717732054ec398d5312f208216e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aa79d27f7a43708d74149ad01dd121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965530e446264d20bd6c52fada9d57b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed77380f43824426bf1066463a7bdaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side, mirror=\"modelscope\")\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a63e71-e7c4-4e5d-9e22-6953d981d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4902aaca95d74dc583f8ac2ad4468c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdbba034bc7473894e4ca8acdc62302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf2f9c59f7b420abb363190a5dede26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348b49df8b824989b415ed3d36815804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1550ed1c87a4f038458ee6780580112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07529cc4206c4ffdaff80a2cb927b686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9296faaf8c4c4505be9df299963d6868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"glue\", task)\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2d7cd5-62b8-4b7a-ac69-338e6319152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFuction\n",
    "\n",
    "class MapFunc(BaseMapFuction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    "\n",
    "\n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1fd5fc-2285-409e-a4e5-cc3c9759d77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      "\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      "\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      "\n",
      " ...\n",
      "\n",
      " [    0,   133,  1154 ...     1,     1,     1],\n",
      "\n",
      " [    0, 12667,  8423 ...     1,     1,     1],\n",
      "\n",
      " [    0, 32478,  1033 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      "\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      "\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      "\n",
      " ...\n",
      "\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      "\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      "\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[32], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, \n",
      "\n",
      " 1, 1, 0, 0, 1, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb606a2-1fb5-415c-bf12-7e6fd324fe0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d0a00cd884444a9a6bcbbefef05a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\n",
      "To disable this warning, you can either:\n",
      "\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"glue\", task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7703d53-1018-4b99-bca0-f566adbc03f5",
   "metadata": {},
   "source": [
    "加载模型并打印微调参数量，可以看到仅有不到0.6%的参数参与了微调。\n",
    "\n",
    "如出现如下告警请忽略，并不影响模型的微调。\n",
    "\n",
    "```text\n",
    "The following parameters in checkpoint files are not loaded:\n",
    "['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.embeddings.position_ids']\n",
    "The following parameters in models are missing parameter:\n",
    "['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c15af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15290f0f173e4561945ef33a5570f1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\n",
      "To disable this warning, you can either:\n",
      "\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "The following parameters in checkpoint files are not loaded:\n",
      "\n",
      "['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.embeddings.position_ids']\n",
      "\n",
      "The following parameters in models are missing parameter:\n",
      "\n",
      "['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,113,540 || all params: 356,423,684 || trainable%: 0.5929852854559463\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True, mirror=\"modelscope\")\n",
    "model = get_peft_model(model, peft_config)\n",
    "# print number of trainable parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a653eb0-a45b-4232-9a90-2a88568f20b3",
   "metadata": {},
   "source": [
    "## 模型微调（prompt tuning）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268ec75-718e-4ae7-b099-9f104b0a53f6",
   "metadata": {},
   "source": [
    "指定优化器和学习率调整策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d3c5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.trainable_params(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53ea25-eb55-49b1-bab5-161288dcd806",
   "metadata": {},
   "source": [
    "打印参与微调的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd66774-4482-448d-a1ee-f09f33cb8579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter (Tensor(shape=[1024, 1024], dtype=Float32, value=[...], name=base_model.classifier.original_module.dense.weight), requires_grad=True),\n",
       " Parameter (Tensor(shape=[1024], dtype=Float32, value=[...], name=base_model.classifier.original_module.dense.bias), requires_grad=True),\n",
       " Parameter (Tensor(shape=[2, 1024], dtype=Float32, value=[...], name=base_model.classifier.original_module.out_proj.weight), requires_grad=True),\n",
       " Parameter (Tensor(shape=[2], dtype=Float32, value=[0. 0.], name=base_model.classifier.original_module.out_proj.bias), requires_grad=True),\n",
       " Parameter (Tensor(shape=[1024, 1024], dtype=Float32, value=[...], name=base_model.classifier.modules_to_save.default.dense.weight), requires_grad=True),\n",
       " Parameter (Tensor(shape=[1024], dtype=Float32, value=[...], name=base_model.classifier.modules_to_save.default.dense.bias), requires_grad=True),\n",
       " Parameter (Tensor(shape=[2, 1024], dtype=Float32, value=[...], name=base_model.classifier.modules_to_save.default.out_proj.weight), requires_grad=True),\n",
       " Parameter (Tensor(shape=[2], dtype=Float32, value=[ 0.00000000e+00  0.00000000e+00], name=base_model.classifier.modules_to_save.default.out_proj.bias), requires_grad=True),\n",
       " Parameter (Tensor(shape=[10, 1024], dtype=Float32, value=[...], name=prompt_encoder.default.embedding.weight), requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print name of trainable parameters\n",
    "model.trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae91b32-2b5e-4084-82c3-a6e52d0193a3",
   "metadata": {},
   "source": [
    "按照如下步骤定义训练逻辑：\n",
    "\n",
    "1. 构建正向计算函数\n",
    "2. 函数变换，获取微分函数\n",
    "3. 定义训练一个step的逻辑\n",
    "4. 遍历训练数据集进行模型训练，同时每一个epoch后，遍历验证数据集获取当前的评价指标（accuracy、f1 score）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d279225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:23<00:00,  1.25s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.696078431372549, 'f1': 0.8181818181818182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:21<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'accuracy': 0.7034313725490197, 'f1': 0.8217967599410898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:20<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'accuracy': 0.6985294117647058, 'f1': 0.8172362555720654}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:21<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: {'accuracy': 0.7156862745098039, 'f1': 0.8253012048192772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:21<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: {'accuracy': 0.7254901960784313, 'f1': 0.8297872340425532}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:21<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: {'accuracy': 0.7156862745098039, 'f1': 0.8226299694189603}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [02:21<00:00,  1.23s/it]\n",
      "\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: {'accuracy': 0.7377450980392157, 'f1': 0.8325508607198748}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 16/115 [00:19<02:01,  1.23s/it]"
     ]
    }
   ],
   "source": [
    "# define forward function\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "# Get gradient function\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "# Define function of one-step training\n",
    "def train_step(**batch):\n",
    "    loss, grads = grad_fn(**batch)\n",
    "    optimizer(grads)\n",
    "    return loss\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train()\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    # Iterate through the dataset\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        loss = train_step(**batch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    # Evaluate while training\n",
    "    model.set_train(False)\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(axis=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        metric.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "    \n",
    "    # Calculate accuracy and f1 score\n",
    "    eval_metric = metric.compute()\n",
    "    print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b45298-e542-4c7d-b702-b5d24e5b8b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "016991f8-0e0d-44c8-96f7-8b2cad54c592"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "ms2.2.14",
   "language": "python",
   "name": "ms2.2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
