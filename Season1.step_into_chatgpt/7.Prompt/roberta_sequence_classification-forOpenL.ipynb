{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f0fdd3",
   "metadata": {},
   "source": [
    "# MindSpore2.4版本在启智社区昇腾环境的适配（大模型案例-prompt_tuning）\n",
    "镜像：mindspore_2_3_910b_cann8\n",
    "\n",
    "原始链接：https://pangu.huaweicloud.com/gallery/asset-detail.html?id=016991f8-0e0d-44c8-96f7-8b2cad54c592"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ac91c",
   "metadata": {},
   "source": [
    "# 基于MindNLP的Roberta模型Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324424c6",
   "metadata": {},
   "source": [
    "安装mindspore, mindnlp及其他依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3f2df1-da30-4009-8b33-80df52be80c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting mindspore==2.4.1\n",
      "  Downloading https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.1/MindSpore/unified/aarch64/mindspore-2.4.1-cp39-cp39-linux_aarch64.whl (335.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.5/335.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (3.20.3)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (2.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (9.0.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (23.2)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (5.9.5)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.6.3)\n",
      "Collecting safetensors>=0.4.0 (from mindspore==2.4.1)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/08/94/7760694760f1e5001bd62c93155b8b7ccb652d1f4d0161d1e72b5bf9581a/safetensors-0.4.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (442 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.4/442.4 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.4.1) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.4.1) (0.41.2)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, mindspore\n",
      "  Attempting uninstall: mindspore\n",
      "    Found existing installation: mindspore 2.3.0\n",
      "    Uninstalling mindspore-2.3.0:\n",
      "      Successfully uninstalled mindspore-2.3.0\n",
      "Successfully installed mindspore-2.4.1 safetensors-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.1/MindSpore/unified/aarch64/mindspore-2.4.1-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b0ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "%env HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e977f",
   "metadata": {},
   "source": [
    "## 模型与数据集加载\n",
    "\n",
    "本案例对roberta-large模型基于GLUE基准数据集进行prompt tuning。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef577ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import mindspore\n",
    "from mindnlp.core.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from mindnlp.dataset import load_dataset\n",
    "from mindnlp.engine import set_seed\n",
    "from mindnlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from mindnlp.common.optimization import get_linear_schedule_with_warmup\n",
    "from mindnlp.peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptTuningConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af061f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_name_or_path = \"AI-ModelScope/roberta-large\"\n",
    "task = \"mrpc\"\n",
    "peft_type = PeftType.PROMPT_TUNING\n",
    "# num_epochs = 20\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949e9cb",
   "metadata": {},
   "source": [
    "prompt tuning配置，任务类型选为\"SEQ_CLS\", 即序列分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9663be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft config\n",
    "peft_config = PromptTuningConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=10)\n",
    "# learning rate\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc55fc7",
   "metadata": {},
   "source": [
    "加载tokenizer。如模型为GPT、OPT或BLOOM类模型，从序列左侧添加padding，其他情况下从序列右侧添加padding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871ebbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:00<00:00, 2.00MB/s]\n",
      "100%|██████████| 878k/878k [00:00<00:00, 5.73MB/s]\n",
      "100%|██████████| 446k/446k [00:00<00:00, 3.62MB/s]\n",
      "100%|██████████| 1.29M/1.29M [00:00<00:00, 8.18MB/s]\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side, mirror=\"modelscope\")\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ef5257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 3668/3668 [00:00<00:00, 134928.72 examples/s]\n",
      "Generating validation split: 100%|██████████| 408/408 [00:00<00:00, 103487.91 examples/s]\n",
      "Generating test split: 100%|██████████| 1725/1725 [00:00<00:00, 309050.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence1': Tensor(shape=[], dtype=String, value= 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'), 'sentence2': Tensor(shape=[], dtype=String, value= 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'), 'label': Tensor(shape=[], dtype=Int64, value= 1), 'idx': Tensor(shape=[], dtype=Int64, value= 0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"glue\", task)\n",
    "print(next(datasets['train'].create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151943cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.dataset import BaseMapFunction\n",
    "\n",
    "class MapFunc(BaseMapFunction):\n",
    "    def __call__(self, sentence1, sentence2, label, idx):\n",
    "        outputs = tokenizer(sentence1, sentence2, truncation=True, max_length=None)\n",
    "        return outputs['input_ids'], outputs['attention_mask'], label\n",
    "\n",
    "\n",
    "def get_dataset(dataset, tokenizer):\n",
    "    input_colums=['sentence1', 'sentence2', 'label', 'idx']\n",
    "    output_columns=['input_ids', 'attention_mask', 'labels']\n",
    "    dataset = dataset.map(MapFunc(input_colums, output_columns),\n",
    "                          input_colums, output_columns)\n",
    "    dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(datasets['train'], tokenizer)\n",
    "eval_dataset = get_dataset(datasets['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99c4ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "[[    0, 10127,  1001 ...     1,     1,     1],\n",
      " [    0,   975, 26802 ...     1,     1,     1],\n",
      " [    0,  1213,    56 ...     1,     1,     1],\n",
      " ...\n",
      " [    0,   133,  1154 ...     1,     1,     1],\n",
      " [    0, 12667,  8423 ...     1,     1,     1],\n",
      " [    0, 32478,  1033 ...     1,     1,     1]]), 'attention_mask': Tensor(shape=[32, 70], dtype=Int64, value=\n",
      "[[1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " ...\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0],\n",
      " [1, 1, 1 ... 0, 0, 0]]), 'labels': Tensor(shape=[32], dtype=Int64, value= [1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, \n",
      " 1, 1, 0, 0, 1, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(next(train_dataset.create_dict_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc17398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 5.75kB [00:00, 15.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"glue\", task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034b5b2",
   "metadata": {},
   "source": [
    "加载模型并打印微调参数量，可以看到仅有不到0.6%的参数参与了微调。\n",
    "\n",
    "如出现如下告警请忽略，并不影响模型的微调。\n",
    "\n",
    "```text\n",
    "The following parameters in checkpoint files are not loaded:\n",
    "['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.embeddings.position_ids']\n",
    "The following parameters in models are missing parameter:\n",
    "['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f929a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.32G/1.32G [01:56<00:00, 12.2MB/s]\n",
      "[WARNING] DEVICE(3899,ffffa583d010,python):2024-12-22-20:24:24.819.971 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_vmm_adapter.h:188] CheckVmmDriverVersion] Driver version is less than 24.0.0, vmm is disabled by default, drvier_version: 23.0.rc2.2\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at AI-ModelScope/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,061,890 || all params: 356,423,684 || trainable%: 0.2979291353713745\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True, mirror=\"modelscope\")\n",
    "model = get_peft_model(model, peft_config)\n",
    "# print number of trainable parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe629f6",
   "metadata": {},
   "source": [
    "## 模型微调（prompt tuning）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ae5a5",
   "metadata": {},
   "source": [
    "指定优化器和学习率调整策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c7ee704",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.trainable_params(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),\n",
    "    num_training_steps=(len(train_dataset) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5b68a",
   "metadata": {},
   "source": [
    "打印参与微调的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d2bff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[1024, 1024], dtype=Float32, value=\n",
       " [[-4.84916121e-02, -1.29634524e-02,  2.16135755e-02 ...  2.64235642e-02, -1.73129626e-02,  5.46947354e-03],\n",
       "  [ 1.14002684e-02,  2.35189125e-03,  1.35929622e-02 ... -2.99772061e-02,  1.13693560e-02, -9.13739577e-03],\n",
       "  [ 2.15256605e-02,  6.29948974e-02, -1.10398978e-02 ... -6.41190819e-03,  2.61987019e-02, -3.97673920e-02],\n",
       "  ...\n",
       "  [-6.10018009e-03,  2.48880149e-03,  3.41544114e-02 ... -5.09967422e-03, -3.12342797e-03,  8.94547254e-03],\n",
       "  [ 3.61969471e-02,  8.10870435e-03, -1.92146900e-03 ... -3.68045643e-02,  1.80197470e-02, -1.78961698e-02],\n",
       "  [ 2.45927437e-03, -1.17309773e-02, -9.71407164e-03 ... -7.21747475e-03, -8.41312669e-03,  1.38750151e-02]]),\n",
       " Tensor(shape=[1024], dtype=Float32, value= [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       " Tensor(shape=[2, 1024], dtype=Float32, value=\n",
       " [[-2.14432161e-02,  2.90536340e-02,  2.31685974e-02 ... -5.82737103e-03, -8.68804567e-03, -3.32077965e-02],\n",
       "  [-2.34791655e-02, -1.38841322e-04,  8.67018010e-03 ... -3.24004292e-02,  9.92231164e-03, -1.32365888e-02]]),\n",
       " Tensor(shape=[2], dtype=Float32, value= [ 0.00000000e+00,  0.00000000e+00]),\n",
       " Tensor(shape=[10, 1024], dtype=Float32, value=\n",
       " [[-1.55804589e-01,  8.45579207e-01, -6.95813656e-01 ... -8.07289600e-01,  1.45514882e+00, -1.23411083e+00],\n",
       "  [ 1.45339954e+00, -1.17388141e+00,  1.80284631e+00 ... -7.75406420e-01, -1.13734949e+00,  4.71715689e-01],\n",
       "  [-3.76855999e-01,  3.67327303e-01,  2.81517267e-01 ...  3.55220623e-02, -1.40278351e+00, -5.00047147e-01],\n",
       "  ...\n",
       "  [ 9.08257514e-02, -1.79791605e+00, -1.27696681e+00 ... -1.74203777e+00, -1.65973697e-03,  2.24076962e+00],\n",
       "  [ 6.95407629e-01,  4.18000519e-02,  1.92043221e+00 ...  3.21290821e-01, -3.31503659e-01,  1.11947632e+00],\n",
       "  [-2.27729559e-01, -9.97637689e-01,  1.26208293e+00 ...  5.30998111e-01,  1.31427443e+00, -6.90508842e-01]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print name of trainable parameters\n",
    "model.trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61576ae",
   "metadata": {},
   "source": [
    "按照如下步骤定义训练逻辑：\n",
    "\n",
    "1. 构建正向计算函数\n",
    "2. 函数变换，获取微分函数\n",
    "3. 定义训练一个step的逻辑\n",
    "4. 遍历训练数据集进行模型训练，同时每一个epoch后，遍历验证数据集获取当前的评价指标（accuracy、f1 score）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0667ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/115 [00:01<02:04,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:07<00:00,  1.71it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:09<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6887254901960784, 'f1': 0.8140556368960467}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.15it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'accuracy': 0.696078431372549, 'f1': 0.8176470588235294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:35<00:00,  3.20it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'accuracy': 0.7107843137254902, 'f1': 0.8217522658610272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.13it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: {'accuracy': 0.6985294117647058, 'f1': 0.8183161004431315}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.17it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: {'accuracy': 0.6985294117647058, 'f1': 0.8177777777777778}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.core import value_and_grad\n",
    "def forward_fn(**batch):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "grad_fn = value_and_grad(forward_fn, tuple(model.parameters()))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.set_train()\n",
    "    train_total_size = train_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(train_dataset.create_dict_iterator(), total=train_total_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = grad_fn(**batch)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    model.set_train(False)\n",
    "    eval_total_size = eval_dataset.get_dataset_size()\n",
    "    for step, batch in enumerate(tqdm(eval_dataset.create_dict_iterator(), total=eval_total_size)):\n",
    "        outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(axis=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        metric.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "    print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de28f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "016991f8-0e0d-44c8-96f7-8b2cad54c592"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
