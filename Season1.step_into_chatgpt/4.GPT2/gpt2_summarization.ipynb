{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d6824d",
   "metadata": {},
   "source": [
    "1. 安装mindspore2.4.1，安装指南详见：[MindSpore安装](https://www.mindspore.cn/install)\n",
    "2. 安装MindNLP及相关依赖，MindNLP官方仓详见：[MindNLP](https://github.com/mindspore-lab/mindnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef9f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting mindspore==2.4.1\n",
      "  Downloading https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.1/MindSpore/unified/aarch64/mindspore-2.4.1-cp39-cp39-linux_aarch64.whl (335.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.5/335.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (3.20.3)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (2.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (9.0.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (23.2)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (5.9.5)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.1) (1.6.3)\n",
      "Collecting safetensors>=0.4.0 (from mindspore==2.4.1)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/08/94/7760694760f1e5001bd62c93155b8b7ccb652d1f4d0161d1e72b5bf9581a/safetensors-0.4.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (442 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.4/442.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.4.1) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.4.1) (0.41.2)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, mindspore\n",
      "  Attempting uninstall: mindspore\n",
      "    Found existing installation: mindspore 2.3.0\n",
      "    Uninstalling mindspore-2.3.0:\n",
      "      Successfully uninstalled mindspore-2.3.0\n",
      "Successfully installed mindspore-2.4.1 safetensors-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.4.1/MindSpore/unified/aarch64/mindspore-2.4.1-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59eba7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting mindnlp\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0f/a8/5a072852d28a51417b5e330b32e6ae5f26b491ef01a15ba968e77f785e69/mindnlp-0.4.0-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mindspore>=2.2.14 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (2.4.1)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (2.32.3)\n",
      "Requirement already satisfied: datasets in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (2.18.0)\n",
      "Collecting evaluate (from mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a2/e7/cbca9e2d2590eb9b5aa8f7ebabe1beb1498f9462d2ecede5c9fd9735faaf/evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers==0.19.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (0.19.1)\n",
      "Requirement already satisfied: safetensors in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (0.4.3)\n",
      "Requirement already satisfied: sentencepiece in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (0.1.99)\n",
      "Requirement already satisfied: regex in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (2023.10.3)\n",
      "Requirement already satisfied: addict in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (2.4.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/ml_dtypes-0.2.0-py3.9-linux-aarch64.egg (from mindnlp) (0.2.0)\n",
      "Collecting pyctcdecode (from mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a5/8a/93e2118411ae5e861d4f4ce65578c62e85d0f1d9cb389bd63bd57130604e/pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: jieba in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp) (0.42.1)\n",
      "Collecting pytest==7.2.0 (from mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/67/68/a5eb36c3a8540594b6035e6cdae40c1ef1b6a2bfacbecc3d1a544583c078/pytest-7.2.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=10.0.0 (from mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/78/66/7c5e44ab2c0123710a5d4692a4ee5931ac438efd7730ac395e305902346e/pillow-11.0.0-cp39-cp39-manylinux_2_28_aarch64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp) (23.1.0)\n",
      "Collecting iniconfig (from pytest==7.2.0->mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp) (23.2)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest==7.2.0->mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp) (1.1.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tokenizers==0.19.1->mindnlp) (0.23.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (3.20.3)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (1.11.3)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (5.9.5)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp) (1.6.3)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (3.12.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (12.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->mindnlp) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp) (2023.7.22)\n",
      "Collecting pygtrie<3.0,>=2.1 (from pyctcdecode->mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ec/cd/bd196b2cf014afb1009de8b0f05ecd54011d881944e62763f3c1b1e8ef37/pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Collecting hypothesis<7,>=6.14 (from pyctcdecode->mindnlp)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/66/cb/44fe7e78c3cfbcb01f905b3b252eff6396e2f2e8e88b2d27b5140a6ac474/hypothesis-6.122.3-py3-none-any.whl (475 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore>=2.2.14->mindnlp) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore>=2.2.14->mindnlp) (0.41.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp) (4.8.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from hypothesis<7,>=6.14->pyctcdecode->mindnlp) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp) (2023.3)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pygtrie, pluggy, pillow, iniconfig, hypothesis, pytest, pyctcdecode, evaluate, mindnlp\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.0.1\n",
      "    Uninstalling Pillow-9.0.1:\n",
      "      Successfully uninstalled Pillow-9.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.36.1 requires pillow<11.0,>=8.0, but you have pillow 11.0.0 which is incompatible.\n",
      "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 11.0.0 which is incompatible.\n",
      "mindformers 0.8.0 requires pydantic==1.10.11, but you have pydantic 2.7.4 which is incompatible.\n",
      "torchvision 0.18.0 requires torch==2.3.0, but you have torch 2.1.0 which is incompatible.\n",
      "modelarts 1.4.4 requires lxml<=4.7.1, but you have lxml 4.9.3 which is incompatible.\n",
      "modelarts 1.4.4 requires pandas<=1.3.4, but you have pandas 2.1.2 which is incompatible.\n",
      "modelarts 1.4.4 requires Pillow<=9.0.1, but you have pillow 11.0.0 which is incompatible.\n",
      "modelarts 1.4.4 requires pyyaml<=6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "modelarts 1.4.4 requires requests<=2.26.0, but you have requests 2.32.3 which is incompatible.\n",
      "modelarts 1.4.4 requires semantic-version<=2.8.5, but you have semantic-version 2.10.0 which is incompatible.\n",
      "modelarts 1.4.4 requires tqdm<=4.62.3, but you have tqdm 4.66.1 which is incompatible.\n",
      "modelarts 1.4.4 requires typing-extensions<=4.0.1, but you have typing-extensions 4.8.0 which is incompatible.\n",
      "modelarts 1.4.4 requires urllib3<=1.26.7, but you have urllib3 2.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3 hypothesis-6.122.3 iniconfig-2.0.0 mindnlp-0.4.0 pillow-11.0.0 pluggy-1.5.0 pyctcdecode-0.5.0 pygtrie-2.5.0 pytest-7.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mindnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a98b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mindformers 0.8.0\n",
      "Uninstalling mindformers-0.8.0:\n",
      "  Successfully uninstalled mindformers-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall mindformers -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a4547",
   "metadata": {},
   "source": [
    "***注：执行如上命令完成安装后，请点击上方的restart kernel图标重启kernel，再进行实验***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a20922",
   "metadata": {},
   "source": [
    "### 数据集加载与处理\n",
    "\n",
    "1. 数据集加载\n",
    "\n",
    "    本次实验使用的是nlpcc2017摘要数据，内容为新闻正文及其摘要，总计50000个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0946e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.utils import http_get\n",
    "\n",
    "# download dataset\n",
    "url = 'https://download.mindspore.cn/toolkits/mindnlp/dataset/text_generation/nlpcc2017/train_with_summ.txt'\n",
    "path = http_get(url, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d85a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore.dataset import TextFileDataset\n",
    "\n",
    "# load dataset\n",
    "dataset = TextFileDataset(str(path), shuffle=False)\n",
    "dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49ef82",
   "metadata": {},
   "source": [
    "**本案例默认在GPU P100上运行，因中文文本，tokenizer使用的是bert tokenizer而非gpt tokenizer等原因，全量数据训练1个epoch的时间约为80分钟。**\n",
    "\n",
    "**为节约时间，我们选取了数据集中很小的一个子集（500条数据）来演示gpt2的微调和推理全流程，但由于数据量不足，会导致模型效果较差。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d948a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing dataset\n",
    "mini_dataset, _ = dataset.split([0.01, 0.99], randomize=False)\n",
    "train_dataset, test_dataset = mini_dataset.split([0.9, 0.1], randomize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af140d",
   "metadata": {},
   "source": [
    "2. 数据预处理\n",
    "\n",
    "    原始数据格式：\n",
    "    ```text\n",
    "    article: [CLS] article_context [SEP]\n",
    "    summary: [CLS] summary_context [SEP]\n",
    "    ```\n",
    "    预处理后的数据格式：\n",
    "\n",
    "    ```text\n",
    "    [CLS] article_context [SEP] summary_context [SEP]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82bfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# preprocess dataset\n",
    "def process_dataset(dataset, tokenizer, batch_size=4, max_seq_len=1024, shuffle=False):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def merge_and_pad(article, summary):\n",
    "        # tokenization\n",
    "        # pad to max_seq_length, only truncate the article\n",
    "        tokenized = tokenizer(text=article, text_pair=summary,\n",
    "                              padding='max_length', truncation='only_first', max_length=max_seq_len)\n",
    "        return tokenized['input_ids'], tokenized['input_ids']\n",
    "    \n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    # change column names to input_ids and labels for the following training\n",
    "    dataset = dataset.map(merge_and_pad, ['article', 'summary'], ['input_ids', 'labels'])\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa07d91",
   "metadata": {},
   "source": [
    "因GPT2无中文的tokenizer，我们使用BertTokenizer替代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71dbb760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindnlp.transformers import BertTokenizer\n",
    "\n",
    "# We use BertTokenizer for tokenizing chinese context.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647f7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = process_dataset(train_dataset, tokenizer, batch_size=4, max_seq_len=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc30afe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[4, 300], dtype=Int64, value=\n",
       " [[ 101, 1724, 3862 ... 3299, 2419,  102],\n",
       "  [ 101,  704, 3173 ... 3341, 3975,  102],\n",
       "  [ 101, 1079, 2159 ... 1745, 8021,  102],\n",
       "  [ 101, 1355, 2357 ...    0,    0,    0]]),\n",
       " Tensor(shape=[4, 300], dtype=Int64, value=\n",
       " [[ 101, 1724, 3862 ... 3299, 2419,  102],\n",
       "  [ 101,  704, 3173 ... 3341, 3975,  102],\n",
       "  [ 101, 1079, 2159 ... 1745, 8021,  102],\n",
       "  [ 101, 1355, 2357 ...    0,    0,    0]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b0122",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "\n",
    "构建GPT2ForSummarization模型，注意***shift right***的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a54bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.core.nn import functional as F\n",
    "from mindnlp.transformers import GPT2LMHeadModel\n",
    "\n",
    "class GPT2ForSummarization(GPT2LMHeadModel):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        labels = None,\n",
    "    ):\n",
    "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        shift_logits = outputs.logits[..., :-1, :]\n",
    "        shift_labels = labels[..., 1:]\n",
    "        # Flatten the tokens\n",
    "        loss = F.cross_entropy(shift_logits.view(-1, shift_logits.shape[-1]), shift_labels.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "        return (loss,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c45443",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3518c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "warmup_steps = 100\n",
    "learning_rate = 1.5e-4\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "num_training_steps = num_epochs * train_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95452db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "[WARNING] DEVICE(3028,ffffa994f010,python):2024-12-23-17:56:18.694.422 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_vmm_adapter.h:188] CheckVmmDriverVersion] Driver version is less than 24.0.0, vmm is disabled by default, drvier_version: 23.0.rc2.2\n"
     ]
    }
   ],
   "source": [
    "from mindspore import nn\n",
    "from mindnlp.transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(vocab_size=len(tokenizer), bos_token_id=tokenizer.cls_token_id, eos_token_id=tokenizer.pad_token_id)\n",
    "model = GPT2ForSummarization(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8591eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of model parameters: 102068736\n"
     ]
    }
   ],
   "source": [
    "# 记录模型参数数量\n",
    "print('number of model parameters: {}'.format(model.num_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e915d2-19d3-46ec-bb64-13a91a228436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.engine import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/gpt2_summarization\",\n",
    "    save_steps=train_dataset.get_dataset_size(),\n",
    "    save_total_limit=3,\n",
    "    logging_steps=1000,\n",
    "    max_steps=num_training_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_steps=warmup_steps\n",
    "    \n",
    ")\n",
    "\n",
    "from mindnlp.engine import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bd258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/113 [00:36<1:08:25, 36.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [02:16<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [02:28<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 148.8578, 'train_samples_per_second': 6.073, 'train_steps_per_second': 0.759, 'train_loss': 7.764800215189436, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=113, training_loss=7.764800215189436, metrics={'train_runtime': 148.8578, 'train_samples_per_second': 6.073, 'train_steps_per_second': 0.759, 'train_loss': 7.764800215189436, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe5469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dataset(dataset, tokenizer, batch_size=1, max_seq_len=1024, max_summary_len=100):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def pad(article):\n",
    "        tokenized = tokenizer(text=article, truncation=True, max_length=max_seq_len-max_summary_len)\n",
    "        return tokenized['input_ids']\n",
    "\n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    dataset = dataset.map(pad, 'article', ['input_ids'])\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ef5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_test_dataset = process_test_dataset(test_dataset, tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8caebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 101,  126, 3299, 8110, 3189, 3241, 8024, 3633,  966, 2844, 1894,\n",
      "        5688,  511, 3727,  704, 2356,  704, 2552, 1278, 7368, 6117, 3890,\n",
      "        7599, 3969, 1048, 4554, 4906, 2844, 1894, 2207, 6145, 8024, 3633,\n",
      "        1762, 3146, 4415, 2843, 3131, 2642, 5442, 4500, 4638, 4289, 1501,\n",
      "        8024, 1762, 3690, 3187, 7344, 1906, 4638, 2658, 1105,  678, 8024,\n",
      "        6158,  671, 4511, 2094,  697, 3613, 3666, 2802,  511,  113, 1290,\n",
      "        1555, 2845,  126, 3299, 8115, 3189,  100, 4276, 3295, 2845, 6887,\n",
      "         114,  126, 3299, 8130, 3189,  677, 1286, 8024, 1290, 1555, 2845,\n",
      "        6381, 5442,  794, 1062, 2128, 3727, 1378, 6356, 3175,  749, 6237,\n",
      "        1168, 8024, 2802,  782, 4511, 2094, 1426, 3378, 2347, 6158, 6121,\n",
      "        3124, 2872, 4522,  511, 2945, 6356, 3175,  792, 5305, 8024,  126,\n",
      "        3299, 8110, 3189, 2496, 3241, 8024, 1728, 1426, 3378, 5326, 3678,\n",
      "        1728, 2843, 3131, 3187, 3126, 3647,  767, 8024, 6628, 1168, 1278,\n",
      "        7368, 4638, 1426, 3378, 2658, 5328, 4080, 1220, 8024, 2199, 2844,\n",
      "        1894, 4991, 2844, 1894, 2207, 6145, 2802,  839, 8024, 2193, 5636,\n",
      "        2207, 6145, 1928, 6956, 1912,  839, 8024, 1059, 6716, 1914, 1905,\n",
      "        6763, 5299, 5302, 2919,  839,  511, 1278, 7368, 2845, 6356, 1400,\n",
      "        8024, 1426, 3378, 6845, 4895, 4385, 1767,  511,  752,  816, 1355,\n",
      "        4495, 1400, 8024, 3696, 6356, 5018,  671, 3198, 7313, 2245, 2458,\n",
      "        6444, 3389, 8024, 7219, 2137, 2066, 4542,  782, 1426, 3378,  511,\n",
      "        7390, 1400, 8024, 1426, 3378, 6158, 6356, 3175,  837, 1542, 8024,\n",
      "        2190, 6824, 3791,  752, 2141,  897, 6371,  679, 6383,  511, 4680,\n",
      "        1184, 8024, 1426, 3378, 1728, 3868, 2066, 2192, 6119, 3996,  752,\n",
      "        8024, 6158, 6356, 3175, 6121, 3124, 2872, 4522, 8115, 3189,  511,\n",
      "        1290, 1555, 2845, 6381, 5442,  794, 3727,  704, 2356,  704, 2552,\n",
      "        1278, 7368,  749, 6237, 1168, 8024, 2207, 6145, 2347, 1139, 7368,\n",
      "        8024, 1726, 1168, 5632, 2346, 4638, 2339,  868, 2266,  855,  511,\n",
      "        1290, 1555, 6381, 5442,  133,  100,  135, 4374,  778, 5356, 6782,\n",
      "        8038, 1290, 1555, 2845,  897, 4943,  102]], dtype=int64), array(['汉中男子因继母抢救无效死亡迁怒护士，将其殴打至头部外伤、多处软组织挫伤；因涉嫌寻衅滋事被拘留(图)'], dtype='<U49')]\n"
     ]
    }
   ],
   "source": [
    "print(next(batched_test_dataset.create_tuple_iterator(output_numpy=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bebbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('./output/gpt2_summarization/checkpoint-113/model.safetensors', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998272b5",
   "metadata": {},
   "source": [
    "由于训练数据量少，epochs数少且tokenizer并未使用gpt tokenizer等因素，模型推理效果会较差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ff4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 5 月 12 日 晚 ， 正 值 护 士 节 。 汉 中 市 中 心 医 院 血 液 风 湿 免 疫 科 护 士 小 袁 ， 正 在 整 理 抢 救 患 者 用 的 物 品 ， 在 毫 无 防 备 的 情 况 下 ， 被 一 男 子 两 次 殴 打 。 ( 华 商 报 5 月 15 日 [UNK] 版 曾 报 道 ) 5 月 22 日 上 午 ， 华 商 报 记 者 从 公 安 汉 台 警 方 了 解 到 ， 打 人 男 子 吴 某 已 被 行 政 拘 留 。 据 警 方 介 绍 ， 5 月 12 日 当 晚 ， 因 吴 某 继 母 因 抢 救 无 效 死 亡 ， 赶 到 医 院 的 吴 某 情 绪 激 动 ， 将 护 士 站 护 士 小 袁 打 伤 ， 导 致 小 袁 头 部 外 伤 ， 全 身 多 处 软 组 织 挫 伤 。 医 院 报 警 后 ， 吴 某 逃 离 现 场 。 事 件 发 生 后 ， 民 警 第 一 时 间 展 开 调 查 ， 锁 定 嫌 疑 人 吴 某 。 随 后 ， 吴 某 被 警 方 传 唤 ， 对 违 法 事 实 供 认 不 讳 。 目 前 ， 吴 某 因 涉 嫌 寻 衅 滋 事 ， 被 警 方 行 政 拘 留 15 日 。 华 商 报 记 者 从 汉 中 市 中 心 医 院 了 解 到 ， 小 袁 已 出 院 ， 回 到 自 己 的 工 作 岗 位 。 华 商 记 者 < [UNK] > 王 亮 编 辑 ： 华 商 报 供 稿 [SEP] [UNK] 。 [SEP] 一 个 月 ， 中 国 人 ， 一 一 人 员 ， 这 ， 他 中 。 图 [SEP] 中 ， [UNK] ， 不 在 一 名 ， 其 中 的 一 子 ， 并 人 在 人 人 的 [UNK] 的 ， 称 ， ，\n"
     ]
    }
   ],
   "source": [
    "model.set_train(False)\n",
    "model.config.eos_token_id = model.config.sep_token_id\n",
    "i = 0\n",
    "for (input_ids, raw_summary) in batched_test_dataset.create_tuple_iterator():\n",
    "    output_ids = model.generate(input_ids, max_new_tokens=50, num_beams=5, no_repeat_ngram_size=2)\n",
    "    output_text = tokenizer.decode(output_ids[0].tolist())\n",
    "    print(output_text)\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e2190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "13ee0843-9209-4b5e-b99f-9ac05d1e0ed6"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
