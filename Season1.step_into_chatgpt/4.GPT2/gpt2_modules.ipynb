{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ff08fc-4052-4e22-8aab-b3579544778f",
   "metadata": {},
   "source": [
    "# GPT2 Masked Multi-head Self-attention详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69894f-46ce-4c18-85d0-8e5418ac70b2",
   "metadata": {},
   "source": [
    "该实验可进行在线体验，在线体验链接（https://pangu.huaweicloud.com/gallery/asset-detail.html?id=6253fbfb-afe6-4727-bca5-5fc726541ab2\n",
    "）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cdf1aa-38a0-4c00-af6e-b76b89ad35a3",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    ">\n",
    ">此为在线运行平台配置python3.9的指南，如在其他环境平台运行案例，请根据实际情况修改如下代码\n",
    ">\n",
    "\n",
    "1. 配置python3.9环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60ce5a7-b42a-4669-affa-99fb526e3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6f72a8-30cd-44ec-a884-4be46b6059bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4c099-ead0-4fa9-8d1e-2eac85a43d9d",
   "metadata": {},
   "source": [
    "***注：以上代码执行完成后，需点击左上角或右上角将kernel更换为python-3.9.0***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f126c-a60f-4e08-8216-02dc63aa9a9b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/ai-gallery/change-kernel.PNG\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe8b0f-8ab4-4658-b64f-5eefb64a25ec",
   "metadata": {},
   "source": [
    "2. 安装mindspore2.2.12、indNLP及相关依赖，MindNLP官方仓详见：MindNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f84d8f-746d-4a87-af68-2dadf693f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install tokenizers==0.15.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!wget https://repo.mindspore.cn/mindspore-lab/mindnlp/daily/202402/20240229/master_20240229160016_c5444092d8cfe47d73e292f25d9a9a56fb04828a_newest/any/mindnlp-0.2.0.20240229-py3-none-any.whl\n",
    "!pip install mindnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965c42b-d37a-42e4-aac9-4d25a4fb33be",
   "metadata": {},
   "source": [
    "***注：执行如上命令完成安装后，请点击上方的restart kernel图标重启kernel，再进行实验***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074df3ae-4bfc-4655-be9f-8041fc211f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code from mindnlp and huggingface transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a161bfb-a15e-4a07-9bb0-688b76f87de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import nn, ops, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab3a91-292b-420d-9b61-c85280dd8dee",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 1- Creating queries, keys, and values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22664691-6db2-4d62-a76a-a4a8a6050199",
   "metadata": {},
   "source": [
    "![gpt2-self-attention-3.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d2591f-26c2-4961-bca3-be30c4352aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 10\n",
    "embed_dim = 768\n",
    "\n",
    "# input x: (1, 10, 768)\n",
    "x = Tensor(np.random.randn(batch_size, seq_len, embed_dim), mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d315a4e-5663-404e-b93d-efb1cf354414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1, 10, 768), (1, 10, 768), (1, 10, 768))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindnlp._legacy.functional import split\n",
    "from mindnlp.transformers.ms_utils import Conv1D\n",
    "\n",
    "# query = Wq * X, key = Wk * X, value = Wv * X\n",
    "# c_attn: (1, 10, 768*3) --> query, key, value: (1, 10, 768), (1, 10, 768), (1, 10, 768) \n",
    "c_attn = Conv1D(3 * embed_dim, embed_dim)\n",
    "query, key, value = split(c_attn(x), embed_dim, axis=2)\n",
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7757e-16e4-4ff9-8a63-3e19767588db",
   "metadata": {},
   "source": [
    "![gpt2-self-attention-split-attention-heads-1.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-split-attention-heads-1.png)\n",
    "\n",
    "![gpt2-self-attention-split-attention-heads-2.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-split-attention-heads-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb7ccac-7cfe-401a-ab32-763de70b4669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_heads(tensor, num_heads, attn_head_size):\n",
    "    \"\"\"\n",
    "    Splits hidden_size dim into attn_head_size and num_heads\n",
    "    \"\"\"\n",
    "    # (batch_size, seq_len, hidden_size) --> (batch_size, seq_len, num_heads, attn_head_size)\n",
    "    new_shape = tensor.shape[:-1] + (num_heads, attn_head_size)\n",
    "    tensor = tensor.view(new_shape)\n",
    "    # (batch_size, seq_len, num_heads, attn_head_size) --> (batch_size, num_heads, seq_len, attn_head_size)\n",
    "    return ops.transpose(tensor, (0, 2, 1, 3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72abe0fe-5225-425b-9bda-0723f3fb27cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 12, 10, 64), (1, 12, 10, 64), (1, 12, 10, 64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 12\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "# (1, 10, 768) --> (1, 10, 12, 64) --> (1, 12, 10, 64)\n",
    "query = split_heads(query, num_heads, head_dim)\n",
    "key = split_heads(key, num_heads, head_dim)\n",
    "value = split_heads(value, num_heads, head_dim)\n",
    "\n",
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f65b2-b291-4ad1-b3ea-8e77e6a254d3",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 2- Scoring\n",
    "\n",
    "![gpt2-self-attention-scoring.png](https://jalammar.github.io/images/gpt2/gpt2-self-attention-scoring.png)\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-scoring-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f952236-de74-4419-9469-7e78d3b7c3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qk点积\n",
    "# q: (1, 12, 10, 64), k^T: (1, 12, 64, 10)\n",
    "# attn_weights: (1, 12, 10, 10)\n",
    "attn_weights = ops.matmul(query, key.swapaxes(-1, -2))\n",
    "\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d6de9-cdb7-40cd-aed1-e4fe059054b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://jalammar.github.io/images/gpt2/transformer-decoder-attention-mask-dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff22248-deff-4962-afae-55772f63f142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 1, 10, 10], dtype=Bool, value=\n",
       "[[[[ True, False, False ... False, False, False],\n",
       "   [ True,  True, False ... False, False, False],\n",
       "   [ True,  True,  True ... False, False, False],\n",
       "   ...\n",
       "   [ True,  True,  True ...  True, False, False],\n",
       "   [ True,  True,  True ...  True,  True, False],\n",
       "   [ True,  True,  True ...  True,  True,  True]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diagonal matrix to implement masked multi-head attention\n",
    "# To ensure not to attend to future information\n",
    "max_positions = seq_len\n",
    "\n",
    "bias = Tensor(np.tril(np.ones((max_positions, max_positions))).reshape(\n",
    "              (1, 1, max_positions, max_positions)), mindspore.bool_)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783a2bc-01dd-4496-a018-ac01e643cd89",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/queries-keys-attention-mask.png)\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/transformer-attention-mask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d957ce17-6df6-4f5e-a262-24ff3a8ce0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindnlp._legacy.functional import where, softmax\n",
    "\n",
    "attn_weights = attn_weights / ops.sqrt(ops.scalar_to_tensor(value.shape[-1]))\n",
    "query_length, key_length = query.shape[-2], key.shape[-2]\n",
    "causal_mask = bias[:, :, key_length - query_length: key_length, :key_length].bool()\n",
    "mask_value = Tensor(np.finfo(np.float32).min, dtype=attn_weights.dtype)\n",
    "attn_weights = where(causal_mask, attn_weights, mask_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee63bfd-f394-4558-9e9f-e102a2fd283c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4028235e+38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(np.float32).min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2faad14-9a3d-4495-8bcc-d7ac2695e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[10, 10], dtype=Float32, value=\n",
       "[[-3.72267663e-01, -3.40282347e+38, -3.40282347e+38 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " [ 4.12474960e-01, -6.20999515e-01, -3.40282347e+38 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " [ 1.29110947e-01,  2.28423685e-01, -1.90024704e-01 ... -3.40282347e+38, -3.40282347e+38, -3.40282347e+38],\n",
       " ...\n",
       " [ 2.14589074e-01,  1.79385528e-01,  2.11229175e-01 ... -8.21841732e-02, -3.40282347e+38, -3.40282347e+38],\n",
       " [-3.86964470e-01,  1.50564313e-03, -7.81135634e-02 ... -8.60612690e-02, -3.31553906e-01, -3.40282347e+38],\n",
       " [ 1.89703301e-01, -7.32186437e-02, -2.44263425e-01 ...  4.69686151e-01, -6.34481907e-01,  6.83065802e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f61883-a535-4135-851c-c41e9c227e18",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/transformer-attention-masked-scores-softmax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9cdaae-ac5a-4bc0-9e59-403d176c0d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = softmax(attn_weights, axis=-1)\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5771f68c-8b35-4b1a-83d1-287b2ce7a47e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[10, 10], dtype=Float32, value=\n",
       "[[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 7.37588942e-01,  2.62411058e-01,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 3.53208542e-01,  3.90087605e-01,  2.56703824e-01 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       " ...\n",
       " [ 1.25348046e-01,  1.21012121e-01,  1.24927595e-01 ...  9.31602344e-02,  0.00000000e+00,  0.00000000e+00],\n",
       " [ 8.72338116e-02,  1.28645703e-01,  1.18800178e-01 ...  1.17859736e-01,  9.22039151e-02,  0.00000000e+00],\n",
       " [ 1.08949542e-01,  8.37606117e-02,  7.05920979e-02 ...  1.44151926e-01,  4.77844179e-02,  9.64947045e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a376e6b-0cd8-434a-aa5b-c647251200fa",
   "metadata": {},
   "source": [
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-multihead-sum-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba1e0ff-5627-4b70-8911-4ffa7383e29d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 10, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = ops.matmul(attn_weights, value)\n",
    "\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952ef91-b1e1-4d5b-9b42-a29f56f8f430",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 3.5- Merge attention heads\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-merge-heads-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e44dd1-4013-4d01-b267-92463b296e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_heads(tensor, num_heads, attn_head_size):\n",
    "    \"\"\"\n",
    "    Merges attn_head_size dim and num_attn_heads dim into hidden_size\n",
    "    \"\"\"\n",
    "    # (batch_size, num_heads, seq_len, attn_head_size) --> (batch_size, seq_len, num_heads, seq_len)\n",
    "    tensor = ops.transpose(tensor, (0, 2, 1, 3))\n",
    "    new_shape = tensor.shape[:-2] + (num_heads * attn_head_size,)\n",
    "    return tensor.view(new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b35f8ee-70b4-4cb4-ad9b-d0b685482b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1, 12, 10, 64) --> (1, 10, 12, 64) --> (1, 10, 768)\n",
    "attn_output = merge_heads(attn_output, num_heads, head_dim)\n",
    "\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14b271-4432-44a0-b1f9-d2632ed2cd5b",
   "metadata": {},
   "source": [
    "## GPT-2 Self-attention: 4- Projecting\n",
    "\n",
    "![](https://jalammar.github.io/images/gpt2/gpt2-self-attention-project-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff788df6-a6a7-4b43-9a76-95eaef4918c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_proj = Conv1D(embed_dim, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c7d4c1f-4ddc-4605-acba-f6e17cbfe2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = c_proj(attn_output)\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300497c-e27a-4fad-b02e-fe2b6a38aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": "",
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "ms2.2.14",
   "language": "python",
   "name": "ms2.2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
