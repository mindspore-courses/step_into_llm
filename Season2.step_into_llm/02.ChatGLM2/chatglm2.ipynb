{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d6ef06-9b7c-4986-b022-edba097094f9",
   "metadata": {},
   "source": [
    "# æ¨ç†ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f9884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-19 12:28:47,192 - mindformers - INFO - Config in the yaml file ./checkpoint_download/glm2/glm2_6b.yaml are used for tokenizer building.\n",
      "2023-08-19 12:28:47,232 - mindformers - INFO - Load the tokenizer name ChatGLM2Tokenizer from the ./checkpoint_download/glm2/glm2_6b.yaml\n",
      "2023-08-19 12:28:47,255 - mindformers - INFO - config in the yaml file ./checkpoint_download/glm2/glm2_6b.yaml are used for tokenizer building.\n",
      "2023-08-19 12:28:47,277 - mindformers - WARNING - Can't find the tokenizer_config.json in the file_dict. The content of file_dict is : {}\n",
      "2023-08-19 12:28:47,287 - mindformers - INFO - build tokenizer class name is: ChatGLM2Tokenizer using args {'bos_token': '<sop>', 'eos_token': '<eop>', 'end_token': '</s>', 'mask_token': '[MASK]', 'gmask_token': '[gMASK]', 'pad_token': '<pad>', 'unk_token': '<unk>', 'vocab_file': './checkpoint_download/glm2/tokenizer.model'}.\n",
      "2023-08-19 12:28:47,367 - mindformers - INFO - ChatGLM2Tokenizer Tokenizer built successfully!\n",
      "2023-08-19 12:30:55,807 - mindformers - INFO - start to read the ckpt file: 12487185277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-19 12:31:41,733 - mindformers - INFO - weights in ./checkpoint_download/glm2/glm2_6b.ckpt are loaded\n",
      "2023-08-19 12:31:41,735 - mindformers - INFO - model built successfully!\n",
      "[Round 1]\n",
      "\n",
      "é—®ï¼šä½ å¥½\n",
      "\n",
      "ç­”ï¼š ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "from mindformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"glm2_6b\")\n",
    "model = AutoModel.from_pretrained(\"glm2_6b\")\n",
    "\n",
    "query = \"ä½ å¥½\"\n",
    "\n",
    "prompted_inputs = tokenizer.build_prompt(query)\n",
    "input_tokens = tokenizer([prompted_inputs])\n",
    "\n",
    "outputs = model.generate(input_tokens[\"input_ids\"], max_length=100)\n",
    "response = tokenizer.decode(outputs)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698715b6-2417-401d-955e-9a810187c76c",
   "metadata": {},
   "source": [
    "# æ¨ç†éƒ¨ç½²ç¤ºä¾‹ - å¯¹è¯æœºå™¨äºº\n",
    "å»ºè®®åœ¨ç»ˆç«¯è¿è¡Œè„šæœ¬chatglm2_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea0b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 03:33:32,005 - mindformers[mindformers/models/base_model.py:110] - INFO - start to read the ckpt file: 12487185277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 03:35:09,629 - mindformers[mindformers/models/base_model.py:116] - INFO - weights in ./checkpoint_download/glm2/glm2_6b.ckpt are loaded\n",
      "2023-11-12 03:35:09,644 - mindformers[mindformers/auto_class.py:291] - INFO - model built successfully!\n",
      "2023-11-12 03:35:15,251 - mindformers[mindformers/auto_class.py:702] - INFO - Config in the yaml file ./checkpoint_download/glm2/glm2_6b.yaml are used for tokenizer building.\n",
      "2023-11-12 03:35:16,582 - mindformers[mindformers/auto_class.py:709] - INFO - Load the tokenizer name ChatGLM2Tokenizer from the ./checkpoint_download/glm2/glm2_6b.yaml\n",
      "2023-11-12 03:35:16,633 - mindformers[mindformers/models/base_tokenizer.py:1979] - INFO - config in the yaml file ./checkpoint_download/glm2/glm2_6b.yaml are used for tokenizer building.\n",
      "2023-11-12 03:35:16,682 - mindformers[mindformers/models/base_tokenizer.py:1989] - WARNING - Can't find the tokenizer_config.json in the file_dict. The content of file_dict is : {}\n",
      "2023-11-12 03:35:16,684 - mindformers[mindformers/models/base_tokenizer.py:1995] - INFO - build tokenizer class name is: ChatGLM2Tokenizer using args {'bos_token': '<sop>', 'eos_token': '<eop>', 'end_token': '</s>', 'mask_token': '[MASK]', 'gmask_token': '[gMASK]', 'pad_token': '<pad>', 'unk_token': '<unk>', 'vocab_file': './checkpoint_download/glm2/tokenizer.model'}.\n",
      "2023-11-12 03:35:16,766 - mindformers[mindformers/auto_class.py:788] - INFO - ChatGLM2Tokenizer Tokenizer built successfully!\n",
      "æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ç”¨æˆ·ï¼š ä½ å¥½\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 03:40:47,389 - mindformers[mindformers/generation/text_generator.py:442] - INFO - total time: 292.39666175842285 s; generated tokens: 28 tokens; generate speed: 0.09576032719256387 tokens/s\n",
      "\u001b[H\u001b[2Jæ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\n",
      "\n",
      "ç”¨æˆ·ï¼šä½ å¥½\n",
      "\n",
      "ChatGLM2-6Bï¼šä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ç”¨æˆ·ï¼š è¯·ä»‹ç»ä¸‹åä¸º\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 03:43:40,087 - mindformers[mindformers/generation/text_generator.py:442] - INFO - total time: 5.809668779373169 s; generated tokens: 108 tokens; generate speed: 18.589700050275948 tokens/s\n",
      "\u001b[H\u001b[2Jæ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\n",
      "\n",
      "ç”¨æˆ·ï¼šä½ å¥½\n",
      "\n",
      "ChatGLM2-6Bï¼šä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
      "\n",
      "ç”¨æˆ·ï¼šè¯·ä»‹ç»ä¸‹åä¸º\n",
      "\n",
      "ChatGLM2-6Bï¼šåä¸ºæ˜¯ä¸€å®¶æ€»éƒ¨ä½äºä¸­å›½çš„å…¨çƒçŸ¥åç§‘æŠ€å…¬å¸,æˆç«‹äº1987å¹´,æ˜¯å…¨çƒé¢†å…ˆçš„ä¿¡æ¯ä¸é€šä¿¡æŠ€æœ¯(ICT)è§£å†³æ–¹æ¡ˆä¾›åº”å•†ä¹‹ä¸€ã€‚\n",
      "\n",
      "åä¸ºçš„ä¸šåŠ¡èŒƒå›´æ¶µç›–äº†ç½‘ç»œã€ç»ˆç«¯ã€äº‘è®¡ç®—ã€è½¯ä»¶ã€èŠ¯ç‰‡ç­‰å¤šä¸ªé¢†åŸŸ,æ——ä¸‹çš„æ™ºèƒ½æ‰‹æœºã€ç”µè„‘ã€å¹³æ¿ç”µè„‘ç­‰æ¶ˆè´¹ç”µå­äº§å“åœ¨å›½å†…å¤–å¸‚åœºä¸Šéƒ½äº«æœ‰è¾ƒé«˜çš„å£°èª‰ã€‚æ­¤å¤–,åä¸ºè¿˜åœ¨5Gã€äººå·¥æ™ºèƒ½ã€äº‘è®¡ç®—ç­‰é¢†åŸŸè¿›è¡Œäº†å¤§é‡çš„æŠ•èµ„å’Œç ”å‘,è‡´åŠ›äºæˆä¸ºå…¨çƒé¢†å…ˆçš„æ•°å­—åŒ–æŠ€æœ¯é¢†å¯¼è€…ã€‚\n",
      "\n",
      "åä¸ºä»¥å…¶é«˜å“è´¨çš„äº§å“å’ŒæœåŠ¡èµ¢å¾—äº†å…¨çƒå®¢æˆ·çš„ä¿¡ä»»å’Œå¥½è¯„,ä¹Ÿæ›¾å› å…¶é¢†å…ˆ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ç”¨æˆ·ï¼š è¯·ä»‹ç»ä¸‹chatglm2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 03:44:03,998 - mindformers[mindformers/generation/text_generator.py:442] - INFO - total time: 2.8868305683135986 s; generated tokens: 54 tokens; generate speed: 18.70563537490363 tokens/s\n",
      "\u001b[H\u001b[2Jæ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\n",
      "\n",
      "ç”¨æˆ·ï¼šä½ å¥½\n",
      "\n",
      "ChatGLM2-6Bï¼šä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
      "\n",
      "ç”¨æˆ·ï¼šè¯·ä»‹ç»ä¸‹åä¸º\n",
      "\n",
      "ChatGLM2-6Bï¼šåä¸ºæ˜¯ä¸€å®¶æ€»éƒ¨ä½äºä¸­å›½çš„å…¨çƒçŸ¥åç§‘æŠ€å…¬å¸,æˆç«‹äº1987å¹´,æ˜¯å…¨çƒé¢†å…ˆçš„ä¿¡æ¯ä¸é€šä¿¡æŠ€æœ¯(ICT)è§£å†³æ–¹æ¡ˆä¾›åº”å•†ä¹‹ä¸€ã€‚\n",
      "\n",
      "åä¸ºçš„ä¸šåŠ¡èŒƒå›´æ¶µç›–äº†ç½‘ç»œã€ç»ˆç«¯ã€äº‘è®¡ç®—ã€è½¯ä»¶ã€èŠ¯ç‰‡ç­‰å¤šä¸ªé¢†åŸŸ,æ——ä¸‹çš„æ™ºèƒ½æ‰‹æœºã€ç”µè„‘ã€å¹³æ¿ç”µè„‘ç­‰æ¶ˆè´¹ç”µå­äº§å“åœ¨å›½å†…å¤–å¸‚åœºä¸Šéƒ½äº«æœ‰è¾ƒé«˜çš„å£°èª‰ã€‚æ­¤å¤–,åä¸ºè¿˜åœ¨5Gã€äººå·¥æ™ºèƒ½ã€äº‘è®¡ç®—ç­‰é¢†åŸŸè¿›è¡Œäº†å¤§é‡çš„æŠ•èµ„å’Œç ”å‘,è‡´åŠ›äºæˆä¸ºå…¨çƒé¢†å…ˆçš„æ•°å­—åŒ–æŠ€æœ¯é¢†å¯¼è€…ã€‚\n",
      "\n",
      "åä¸ºä»¥å…¶é«˜å“è´¨çš„äº§å“å’ŒæœåŠ¡èµ¢å¾—äº†å…¨çƒå®¢æˆ·çš„ä¿¡ä»»å’Œå¥½è¯„,ä¹Ÿæ›¾å› å…¶é¢†å…ˆ\n",
      "\n",
      "ç”¨æˆ·ï¼šè¯·ä»‹ç»ä¸‹chatglm2\n",
      "\n",
      "ChatGLM2-6Bï¼šChatGLM2-6B æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºæ¸…åå¤§å­¦ KEG å®éªŒå®¤ä¸æ™ºè°± AI äº 2023 å¹´è”åˆè®­ç»ƒçš„è¯­è¨€æ¨¡å‹ GLM2-6B å¼€å‘è€Œæˆï¼Œå¯ä»¥é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜å’Œè¦æ±‚æä¾›é€‚å½“çš„ç­”å¤å’Œæ”¯æŒã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ç”¨æˆ·ï¼š stop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import signal\n",
    "import readline\n",
    "\n",
    "import time\n",
    "import mindspore as ms\n",
    "from mindformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"Ascend\", device_id=0)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"glm2_6b\")\n",
    "# å¯ä»¥åœ¨æ­¤ä½¿ç”¨ä¸‹è¡Œä»£ç æŒ‡å®šè‡ªå®šä¹‰æƒé‡è¿›è¡Œæ¨ç†ï¼Œé»˜è®¤ä½¿ç”¨è‡ªåŠ¨ä»obsä¸Šä¸‹è½½çš„é¢„è®­ç»ƒæƒé‡\n",
    "# config.checkpoint_name_or_path = \"/path/to/glm2_6b_finetune.ckpt\"\n",
    "config.use_past = True\n",
    "model = AutoModel.from_config(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"glm2_6b\")\n",
    "\n",
    "os_name = platform.system()\n",
    "clear_command = 'cls' if os_name == 'Windows' else 'clear'\n",
    "stop_stream = False\n",
    "\n",
    "\n",
    "def build_prompt(history):\n",
    "    prompt = \"æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\"\n",
    "    for query, response in history:\n",
    "        prompt += f\"\\n\\nç”¨æˆ·ï¼š{query}\"\n",
    "        prompt += f\"\\n\\nChatGLM2-6Bï¼š{response}\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def signal_handler(signal, frame):\n",
    "    global stop_stream\n",
    "    stop_stream = True\n",
    "\n",
    "\n",
    "def main():\n",
    "    history = []\n",
    "    global stop_stream\n",
    "    print(\"æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\")\n",
    "    while True:\n",
    "        query = input(\"\\nç”¨æˆ·ï¼š\")\n",
    "        if query.strip() == \"stop\":\n",
    "            break\n",
    "        if query.strip() == \"clear\":\n",
    "            history = []\n",
    "            os.system(clear_command)\n",
    "            print(\"æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\")\n",
    "            continue\n",
    "        count = 0\n",
    "        \n",
    "        # prompt: [Round 1]\\n\\né—®ï¼š{query}\\n\\nç­”ï¼š \n",
    "        prompted_inputs = tokenizer.build_prompt(query)\n",
    "        inputs = tokenizer(prompted_inputs)['input_ids']\n",
    "        outputs = model.generate(inputs, max_length=128)\n",
    "        response = tokenizer.decode(outputs)[0].split(\"ç­”ï¼š \")[-1]\n",
    "        history = history + [(query, response)]\n",
    "\n",
    "        if stop_stream:\n",
    "            stop_stream = False\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "            if count % 8 == 0:\n",
    "                os.system(clear_command)\n",
    "                print(build_prompt(history), flush=True)\n",
    "                signal.signal(signal.SIGINT, signal_handler)\n",
    "        os.system(clear_command)\n",
    "        print(build_prompt(history), flush=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
