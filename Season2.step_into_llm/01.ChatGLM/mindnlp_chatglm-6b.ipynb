{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda25ed9-8a0f-4606-a07a-f6c0ba5ee499",
   "metadata": {},
   "source": [
    "该实验可进行在线体验，在线体验链接（https://pangu.huaweicloud.com/gallery/asset-detail.html?id=cdc88c83-1ac2-4862-b822-3ab200b01736\n",
    "）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014a89a-05f5-446a-bc53-dd048c6c4997",
   "metadata": {},
   "source": [
    "## MindNLP ChatGLM-6B StreamChat\n",
    "\n",
    "本案例基于MindNLP和ChatGLM-6B实现一个聊天应用。**支持流式回复**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5391a-8921-4185-9397-d081064cc131",
   "metadata": {},
   "source": [
    "## 1. 效果展示\n",
    "\n",
    "\n",
    "<video controls width=\"500\" height=\"400\" src=\"https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/musicgen/chatglm6b-streamchat-demo.mp4\">animation</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb420814-0aaf-4244-9c4b-70e087c509d7",
   "metadata": {},
   "source": [
    "## 2. 案例体验\n",
    "🔹 本案例需使用 P100 及以上规格运行，请确保运行规格一致，可按照下图切换规格。\n",
    "\n",
    "![](https://modelarts-labs-bj4-v2.obs.cn-north-4.myhuaweicloud.com/case_zoo/chatglm3/image/1.png)\n",
    "\n",
    "🔹 点击Run in ModelArts，将会进入到ModelArts CodeLab中，这时需要你登录华为云账号，如果没有账号，则需要注册一个，且要进行实名认证，参考[《ModelArts准备工作_简易版》](https://developer.huaweicloud.com/develop/aigallery/article/detail?id=4ce709d6-eb25-4fa4-b214-e2e5d6b7919c) 即可完成账号注册和实名认证。 登录之后，等待片刻，即可进入到CodeLab的运行环境\n",
    "\n",
    "🔹 出现 Out Of Memory ，请检查是否为您的参数配置过高导致，修改参数配置，重启kernel或更换更高规格资源进行规避❗❗❗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a579a34-88f2-4fe3-94f1-88a6597a4a13",
   "metadata": {},
   "source": [
    "### 2.1 环境安装\n",
    "\n",
    "\n",
    "运行如下两个代码块，创建python-3.9.0环境并在notebook的kernel显示选项。\n",
    "\n",
    "> 注意：\n",
    ">\n",
    "> 此为在线运行平台配置python3.9的指南，如在其他环境平台运行案例，请根据实际情况修改如下代码。\n",
    ">\n",
    "> 以下两个代码块仅能运行一次，多次运行会出现kernel报错。\n",
    ">\n",
    "> 如出现多次运行导致的kernel报错，请终止实例（点击右上角“停止NoteBook实例”的圆形图标），并重启实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefd157a-27bd-41e8-8618-7c8290b237c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d943c07-1a1f-42f9-a9e7-605329b8677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02075d-62bf-4466-a5b2-039317d1a233",
   "metadata": {},
   "source": [
    "创建完成后，稍等片刻，或刷新页面，点击右上角（或左上角）kernel选择python-3.9.0\n",
    "\n",
    "![change-kernel](https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/ai-gallery/change-kernel.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9123d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!wget https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/mindnlp_install/mindnlp-0.3.1-py3-none-any.whl\n",
    "!pip install mindnlp\n",
    "!pip install gradio mdtex2html -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install ipywidgets -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d43d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!wget -P /home/ma-user/work https://openi.pcl.ac.cn/lvyufeng/frpc-gradio/raw/branch/master/frpc_linux_amd64\n",
    "!cp /home/ma-user/work/frpc_linux_amd64 /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2\n",
    "!chmod +x /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6703d3e-8451-47e7-bac8-401cdb039be7",
   "metadata": {},
   "source": [
    "## 3. 代码开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8ee640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "\n",
      "Loading model cost 0.793 seconds.\n",
      "\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f59dbc2924541a3bc96e07b8e2bb46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mindnlp.transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import gradio as gr\n",
    "import mdtex2html\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('ZhipuAI/ChatGLM-6B', mirror=\"modelscope\").half()\n",
    "model.set_train(False)\n",
    "tokenizer = AutoTokenizer.from_pretrained('ZhipuAI/ChatGLM-6B', mirror=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fc7ad5-b210-4318-8897-af50b8e6ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/mindnlp/transformers/generation/utils.py:1402: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://hf-mirror.com/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "The dtype of attention mask (Float32) is not bool\n",
      "\n",
      "[WARNING] KERNEL(13801,7f07367fc700,python):2024-05-26-00:31:43.026.035 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel.cc:40] CheckDeviceSm] It is recommended to use devices with a computing capacity >= 7, but the current device's computing capacity is 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好👋！我是人工智能助手 ChatGLM-6B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '你好'\n",
    "history = []\n",
    "response, _ = model.chat(tokenizer, prompt, history=history, max_length=20)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e589553-2617-4a2c-a330-d4d6029d21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Union, Optional\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import mdtex2html\n",
    "\n",
    "#将文本中的字符转为网页上可以支持的字符，避免被误认为是HTML标签\n",
    "def parse_text(text):\n",
    "    \"\"\"copy from https://github.com/GaiZhenbiao/ChuanhuChatGPT/\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\"+line\n",
    "    text = \"\".join(lines)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff6df8-6534-4b8b-983c-8478b38a0fbf",
   "metadata": {},
   "source": [
    "## 3.2 基于 Gradio 创建聊天应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e943b3-16de-49b4-85f2-1e86001ce7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写Gradio调用函数\n",
    "\n",
    "#采用流聊天方式（stream_chat）调用模型，使得生成答案有逐字生成的效果\n",
    "def predict(input, chatbot, max_length, top_p, temperature, history):\n",
    "    chatbot.append((parse_text(input), \"\"))\n",
    "    for response, history in model.stream_chat(tokenizer, input, history, max_length=max_length, top_p=top_p,\n",
    "                                               temperature=temperature):\n",
    "        chatbot[-1] = (parse_text(input), parse_text(response))       \n",
    "\n",
    "        yield chatbot, history\n",
    "\n",
    "#去除输入框的内容\n",
    "def reset_user_input():\n",
    "    return gr.update(value='')\n",
    "\n",
    "#清除状态\n",
    "def reset_state():\n",
    "    return [], [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6fff57-d324-4d54-b529-bc2c293689bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Running on public URL: https://ecf4251e97eec93b96.gradio.live\n",
      "\n",
      "\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ecf4251e97eec93b96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#运行Gradio界面，运行成功后点击“Running on public URL”后的网页链接即可体验\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"\"\"<h1 align=\"center\">MindNLP ChatGLM-6B StreamChat</h1>\"\"\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            with gr.Column(scale=12):\n",
    "                user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=3, container=False)\n",
    "            with gr.Column(min_width=32, scale=1):\n",
    "                with gr.Row():\n",
    "                    submitBtn = gr.Button(\"一键开聊\", variant=\"primary\")\n",
    "                    emptyBtn = gr.Button(\"清除历史\")\n",
    "            with gr.Column(scale=1):\n",
    "                max_length = gr.Slider(0, 4096, value=2048, step=1.0, label=\"Maximum length\", interactive=True)\n",
    "                top_p = gr.Slider(0, 1, value=0.7, step=0.01, label=\"Top P\", interactive=True)\n",
    "                temperature = gr.Slider(0, 1, value=0.95, step=0.01, label=\"Temperature\", interactive=True)               \n",
    "\n",
    "    history = gr.State([])\n",
    "\n",
    "    submitBtn.click(predict, [user_input, chatbot, max_length, top_p, temperature, history], [chatbot, history],\n",
    "                    show_progress=True)\n",
    "    submitBtn.click(reset_user_input, [], [user_input])\n",
    "\n",
    "    emptyBtn.click(reset_state, outputs=[chatbot, history], show_progress=True)\n",
    "\n",
    "demo.queue().launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a6c98-d42a-4470-a1e9-40714a17642e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "cdc88c83-1ac2-4862-b822-3ab200b01736"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "ms2.2.14",
   "language": "python",
   "name": "ms2.2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
