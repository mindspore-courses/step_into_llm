{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c014a89a-05f5-446a-bc53-dd048c6c4997",
   "metadata": {},
   "source": [
    "## MindNLP ChatGLM-6B StreamChat\n",
    "\n",
    "æœ¬æ¡ˆä¾‹åŸºäºMindNLPå’ŒChatGLM-6Bå®ç°ä¸€ä¸ªèŠå¤©åº”ç”¨ã€‚**æ”¯æŒæµå¼å›å¤**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda25ed9-8a0f-4606-a07a-f6c0ba5ee499",
   "metadata": {},
   "source": [
    "è¯¥å®éªŒå¯è¿›è¡Œåœ¨çº¿ä½“éªŒï¼Œåœ¨çº¿ä½“éªŒé“¾æ¥ï¼ˆhttps://pangu.huaweicloud.com/gallery/asset-detail.html?id=cdc88c83-1ac2-4862-b822-3ab200b01736\n",
    "ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5391a-8921-4185-9397-d081064cc131",
   "metadata": {},
   "source": [
    "## 1. æ•ˆæœå±•ç¤º\n",
    "\n",
    "\n",
    "<video controls width=\"500\" height=\"400\" src=\"https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/musicgen/chatglm6b-streamchat-demo.mp4\">animation</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb420814-0aaf-4244-9c4b-70e087c509d7",
   "metadata": {},
   "source": [
    "## 2. æ¡ˆä¾‹ä½“éªŒ\n",
    "ğŸ”¹ æœ¬æ¡ˆä¾‹éœ€ä½¿ç”¨ P100 åŠä»¥ä¸Šè§„æ ¼è¿è¡Œï¼Œè¯·ç¡®ä¿è¿è¡Œè§„æ ¼ä¸€è‡´ï¼Œå¯æŒ‰ç…§ä¸‹å›¾åˆ‡æ¢è§„æ ¼ã€‚\n",
    "\n",
    "![](https://modelarts-labs-bj4-v2.obs.cn-north-4.myhuaweicloud.com/case_zoo/chatglm3/image/1.png)\n",
    "\n",
    "ğŸ”¹ ç‚¹å‡»Run in ModelArtsï¼Œå°†ä¼šè¿›å…¥åˆ°ModelArts CodeLabä¸­ï¼Œè¿™æ—¶éœ€è¦ä½ ç™»å½•åä¸ºäº‘è´¦å·ï¼Œå¦‚æœæ²¡æœ‰è´¦å·ï¼Œåˆ™éœ€è¦æ³¨å†Œä¸€ä¸ªï¼Œä¸”è¦è¿›è¡Œå®åè®¤è¯ï¼Œå‚è€ƒ[ã€ŠModelArtså‡†å¤‡å·¥ä½œ_ç®€æ˜“ç‰ˆã€‹](https://developer.huaweicloud.com/develop/aigallery/article/detail?id=4ce709d6-eb25-4fa4-b214-e2e5d6b7919c) å³å¯å®Œæˆè´¦å·æ³¨å†Œå’Œå®åè®¤è¯ã€‚ ç™»å½•ä¹‹åï¼Œç­‰å¾…ç‰‡åˆ»ï¼Œå³å¯è¿›å…¥åˆ°CodeLabçš„è¿è¡Œç¯å¢ƒ\n",
    "\n",
    "ğŸ”¹ å‡ºç° Out Of Memory ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºæ‚¨çš„å‚æ•°é…ç½®è¿‡é«˜å¯¼è‡´ï¼Œä¿®æ”¹å‚æ•°é…ç½®ï¼Œé‡å¯kernelæˆ–æ›´æ¢æ›´é«˜è§„æ ¼èµ„æºè¿›è¡Œè§„é¿â—â—â—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a579a34-88f2-4fe3-94f1-88a6597a4a13",
   "metadata": {},
   "source": [
    "### 2.1 ç¯å¢ƒå®‰è£…\n",
    "\n",
    "\n",
    "è¿è¡Œå¦‚ä¸‹ä¸¤ä¸ªä»£ç å—ï¼Œåˆ›å»ºpython-3.9.0ç¯å¢ƒå¹¶åœ¨notebookçš„kernelæ˜¾ç¤ºé€‰é¡¹ã€‚\n",
    "\n",
    "> æ³¨æ„ï¼š\n",
    ">\n",
    "> æ­¤ä¸ºåœ¨çº¿è¿è¡Œå¹³å°é…ç½®python3.9çš„æŒ‡å—ï¼Œå¦‚åœ¨å…¶ä»–ç¯å¢ƒå¹³å°è¿è¡Œæ¡ˆä¾‹ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹å¦‚ä¸‹ä»£ç ã€‚\n",
    ">\n",
    "> ä»¥ä¸‹ä¸¤ä¸ªä»£ç å—ä»…èƒ½è¿è¡Œä¸€æ¬¡ï¼Œå¤šæ¬¡è¿è¡Œä¼šå‡ºç°kernelæŠ¥é”™ã€‚\n",
    ">\n",
    "> å¦‚å‡ºç°å¤šæ¬¡è¿è¡Œå¯¼è‡´çš„kernelæŠ¥é”™ï¼Œè¯·ç»ˆæ­¢å®ä¾‹ï¼ˆç‚¹å‡»å³ä¸Šè§’â€œåœæ­¢NoteBookå®ä¾‹â€çš„åœ†å½¢å›¾æ ‡ï¼‰ï¼Œå¹¶é‡å¯å®ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefd157a-27bd-41e8-8618-7c8290b237c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!/home/ma-user/anaconda3/bin/conda create -n python-3.9.0 python=3.9.0 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "!/home/ma-user/anaconda3/envs/python-3.9.0/bin/pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d943c07-1a1f-42f9-a9e7-605329b8677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "   \"display_name\": \"python-3.9.0\",\n",
    "   \"env\": {\n",
    "      \"PATH\": \"/home/ma-user/anaconda3/envs/python-3.9.0/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin\"\n",
    "   },\n",
    "   \"language\": \"python\",\n",
    "   \"argv\": [\n",
    "      \"/home/ma-user/anaconda3/envs/python-3.9.0/bin/python\",\n",
    "      \"-m\",\n",
    "      \"ipykernel\",\n",
    "      \"-f\",\n",
    "      \"{connection_file}\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\"):\n",
    "    os.mkdir(\"/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/\")\n",
    "\n",
    "with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.9.0/kernel.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02075d-62bf-4466-a5b2-039317d1a233",
   "metadata": {},
   "source": [
    "åˆ›å»ºå®Œæˆåï¼Œç¨ç­‰ç‰‡åˆ»ï¼Œæˆ–åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»å³ä¸Šè§’ï¼ˆæˆ–å·¦ä¸Šè§’ï¼‰kernelé€‰æ‹©python-3.9.0\n",
    "\n",
    "![change-kernel](https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/imgs/ai-gallery/change-kernel.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9123d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.14/MindSpore/unified/x86_64/mindspore-2.2.14-cp39-cp39-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!wget https://mindspore-demo.obs.cn-north-4.myhuaweicloud.com/mindnlp_install/mindnlp-0.3.1-py3-none-any.whl\n",
    "!pip install mindnlp\n",
    "!pip install gradio mdtex2html -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install ipywidgets -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d43d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "!wget -P /home/ma-user/work https://openi.pcl.ac.cn/lvyufeng/frpc-gradio/raw/branch/master/frpc_linux_amd64\n",
    "!cp /home/ma-user/work/frpc_linux_amd64 /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2\n",
    "!chmod +x /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/gradio/frpc_linux_amd64_v0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6703d3e-8451-47e7-bac8-401cdb039be7",
   "metadata": {},
   "source": [
    "## 3. ä»£ç å¼€å‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8ee640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "\n",
      "Loading model cost 0.793 seconds.\n",
      "\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f59dbc2924541a3bc96e07b8e2bb46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mindnlp.transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import gradio as gr\n",
    "import mdtex2html\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('ZhipuAI/ChatGLM-6B', mirror=\"modelscope\").half()\n",
    "model.set_train(False)\n",
    "tokenizer = AutoTokenizer.from_pretrained('ZhipuAI/ChatGLM-6B', mirror=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fc7ad5-b210-4318-8897-af50b8e6ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages/mindnlp/transformers/generation/utils.py:1402: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://hf-mirror.com/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "The dtype of attention mask (Float32) is not bool\n",
      "\n",
      "[WARNING] KERNEL(13801,7f07367fc700,python):2024-05-26-00:31:43.026.035 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel.cc:40] CheckDeviceSm] It is recommended to use devices with a computing capacity >= 7, but the current device's computing capacity is 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'ä½ å¥½'\n",
    "history = []\n",
    "response, _ = model.chat(tokenizer, prompt, history=history, max_length=20)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e589553-2617-4a2c-a330-d4d6029d21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Union, Optional\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import mdtex2html\n",
    "\n",
    "#å°†æ–‡æœ¬ä¸­çš„å­—ç¬¦è½¬ä¸ºç½‘é¡µä¸Šå¯ä»¥æ”¯æŒçš„å­—ç¬¦ï¼Œé¿å…è¢«è¯¯è®¤ä¸ºæ˜¯HTMLæ ‡ç­¾\n",
    "def parse_text(text):\n",
    "    \"\"\"copy from https://github.com/GaiZhenbiao/ChuanhuChatGPT/\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\"+line\n",
    "    text = \"\".join(lines)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff6df8-6534-4b8b-983c-8478b38a0fbf",
   "metadata": {},
   "source": [
    "## 3.2 åŸºäº Gradio åˆ›å»ºèŠå¤©åº”ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e943b3-16de-49b4-85f2-1e86001ce7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¼–å†™Gradioè°ƒç”¨å‡½æ•°\n",
    "\n",
    "#é‡‡ç”¨æµèŠå¤©æ–¹å¼ï¼ˆstream_chatï¼‰è°ƒç”¨æ¨¡å‹ï¼Œä½¿å¾—ç”Ÿæˆç­”æ¡ˆæœ‰é€å­—ç”Ÿæˆçš„æ•ˆæœ\n",
    "def predict(input, chatbot, max_length, top_p, temperature, history):\n",
    "    chatbot.append((parse_text(input), \"\"))\n",
    "    for response, history in model.stream_chat(tokenizer, input, history, max_length=max_length, top_p=top_p,\n",
    "                                               temperature=temperature):\n",
    "        chatbot[-1] = (parse_text(input), parse_text(response))       \n",
    "\n",
    "        yield chatbot, history\n",
    "\n",
    "#å»é™¤è¾“å…¥æ¡†çš„å†…å®¹\n",
    "def reset_user_input():\n",
    "    return gr.update(value='')\n",
    "\n",
    "#æ¸…é™¤çŠ¶æ€\n",
    "def reset_state():\n",
    "    return [], [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6fff57-d324-4d54-b529-bc2c293689bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Running on public URL: https://ecf4251e97eec93b96.gradio.live\n",
      "\n",
      "\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ecf4251e97eec93b96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#è¿è¡ŒGradioç•Œé¢ï¼Œè¿è¡ŒæˆåŠŸåç‚¹å‡»â€œRunning on public URLâ€åçš„ç½‘é¡µé“¾æ¥å³å¯ä½“éªŒ\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"\"\"<h1 align=\"center\">MindNLP ChatGLM-6B StreamChat</h1>\"\"\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            with gr.Column(scale=12):\n",
    "                user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=3, container=False)\n",
    "            with gr.Column(min_width=32, scale=1):\n",
    "                with gr.Row():\n",
    "                    submitBtn = gr.Button(\"ä¸€é”®å¼€èŠ\", variant=\"primary\")\n",
    "                    emptyBtn = gr.Button(\"æ¸…é™¤å†å²\")\n",
    "            with gr.Column(scale=1):\n",
    "                max_length = gr.Slider(0, 4096, value=2048, step=1.0, label=\"Maximum length\", interactive=True)\n",
    "                top_p = gr.Slider(0, 1, value=0.7, step=0.01, label=\"Top P\", interactive=True)\n",
    "                temperature = gr.Slider(0, 1, value=0.95, step=0.01, label=\"Temperature\", interactive=True)               \n",
    "\n",
    "    history = gr.State([])\n",
    "\n",
    "    submitBtn.click(predict, [user_input, chatbot, max_length, top_p, temperature, history], [chatbot, history],\n",
    "                    show_progress=True)\n",
    "    submitBtn.click(reset_user_input, [], [user_input])\n",
    "\n",
    "    emptyBtn.click(reset_state, outputs=[chatbot, history], show_progress=True)\n",
    "\n",
    "demo.queue().launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a6c98-d42a-4470-a1e9-40714a17642e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "cdc88c83-1ac2-4862-b822-3ab200b01736"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "ms2.2.14",
   "language": "python",
   "name": "ms2.2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
