{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73b7cdc",
   "metadata": {},
   "source": [
    "# ChatGLM4èŠå¤©æœºå™¨äºº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80128802-8a28-45e1-a728-4e673abfdb3e",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒé…ç½®\n",
    "\n",
    "    python =3.9\n",
    "    mindspore = 2.3.1\n",
    "    mindnlp = 0.4.0\n",
    "    jieba\n",
    "    tiktoken\n",
    "\n",
    "**åœ¨çº¿è¿è¡Œä»£ç å¹³å°é“¾æ¥ï¼š**\n",
    "- 1. [åä¸ºäº‘AI Gallery](https://pangu.huaweicloud.com/gallery/asset-detail.html?id=cdc88c83-1ac2-4862-b822-3ab200b01736)\n",
    "- 2. [å¤§æ¨¡å‹å¹³å°AIå®éªŒå®¤ç»Ÿä¸€å…¥å£](https://xihe.mindspore.cn/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265300fd-3bf5-4df6-9248-1b27cd4f570f",
   "metadata": {},
   "source": [
    "## ä»£ç å¼€å‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897d4ee9-b2b2-4de5-9f4f-7be4bc49b67a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.022 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c147f60104856b73d7926b515b038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346d01049dbb4c14835b6ed02dbaf843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/2.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': Tensor(shape=[1, 6], dtype=Int64, value=\n",
      "[[151331, 151333, 151336,    198, 109377, 151337]]), 'attention_mask': Tensor(shape=[1, 6], dtype=Int64, value=\n",
      "[[1, 1, 1, 1, 1, 1]]), 'position_ids': Tensor(shape=[1, 6], dtype=Int64, value=\n",
      "[[0, 1, 2, 3, 4, 5]])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625d52cf4fdb4d1eb9ce8b55ca1b7157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e4ecd958c44d8eb633ca77d00ecdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/28.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94faf6367faf4f1d856616f8c6b1ec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023b7f7f2d064c4ca471aff202580ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ff62ab8de43b89b544bb6d44c5873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a3dc795b11468cb624f33d40ee11ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16711ed1b05470faa57b58d35249136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596f9f1e630147df9d6938c5ec612719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fe58080b954d41acba37d4a6a9a972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610201d7e744e8ea2405cfd746b0214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbefd4e08be24c179f094c1865f65e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e719b99fd9f744d58ed1497fa24e9785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4d87257fdf47efaf539558c62ede0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b623e677c03847629806f35e0400c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51a83a543764c15a6b3899dc2c36fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/207 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindnlp.core import no_grad\n",
    "from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from mindspore._c_expression import _framework_profiler_step_start\n",
    "from mindspore._c_expression import _framework_profiler_step_end\n",
    "# åŠ è½½tokenizeræ–‡ä»¶\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ZhipuAI/glm-4-9b-chat\", mirror='modelscope')\n",
    "\n",
    "query = \"ä½ å¥½\"\n",
    "\n",
    "inputs = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": query}],\n",
    "                                       add_generation_prompt=True,\n",
    "                                       tokenize=True,\n",
    "                                       return_tensors=\"ms\",\n",
    "                                       return_dict=True\n",
    "                                       )\n",
    "print(inputs)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"ZhipuAI/glm-4-9b-chat\",\n",
    "    mirror='modelscope',\n",
    "    ms_dtype=mindspore.float16,\n",
    ").eval()\n",
    "\n",
    "# _framework_profiler_step_start()\n",
    "gen_kwargs = {\"max_length\": 100, \"do_sample\": True, \"top_k\": 1}\n",
    "with no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# _framework_profiler_step_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b066153-0ae4-4161-aaec-e35f885d107a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
